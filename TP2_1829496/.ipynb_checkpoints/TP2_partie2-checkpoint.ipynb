{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction a PyTorch\n",
    "\n",
    "Based on https://github.com/mila-udem/welcome_tutorials/tree/master/pytorch By Sandeep Subramanian, https://github.com/jcjohnson/pytorch-examples by Justin Johnson and official documentation http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor\n",
    "\n",
    "Tensors are similar to numpy array, but they can also be used on GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "# convert numpy array to tensor\n",
    "torch.from_numpy(np.array([1,2,3,4]))  # LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.], dtype=torch.float64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.array([1.,2,3,4]))  # Double Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor([1,2,3,4])\n",
    "torch.Tensor([1,2,3,4])  # float tensor by default, can change it with torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([1,2,3,4])\n",
    "# HI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.4142, 1.7321, 2.0000])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sqrt()  # similar functionality as numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "x = x.view(-1, 1)  # the torch reshape function\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [2., 2.],\n",
       "        [3., 3.],\n",
       "        [4., 4.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([x, x], 1)  # concatenate 2 vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "\n",
    "Autograd provides automatic differentiation on all operations perform on tensors. To be able to use Autograd, you must wrap your tensors in a Variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], requires_grad=True)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(x, requires_grad=False)\n",
    "w = Variable(torch.ones(4, 1), requires_grad=True)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "dot: Expected 1-D argument self, but got 2-D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-2cfa5d8249c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dot: Expected 1-D argument self, but got 2-D"
     ]
    }
   ],
   "source": [
    "z = torch.dot(w, x)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optim and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([w], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'z' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-d1156426382c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'z' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "z.backward()\n",
    "print(w.grad)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.9900\n",
      " 0.9800\n",
      " 0.9700\n",
      " 0.9600\n",
      "[torch.FloatTensor of size 4x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "dot: Expected 1-D argument self, but got 2-D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-2cd26b6fc9ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dot: Expected 1-D argument self, but got 2-D"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.MSELoss()\n",
    "z = torch.dot(w, x)\n",
    "target = Variable(torch.zeros(1))\n",
    "optimizer.zero_grad()\n",
    "loss = loss_fn(z, target)\n",
    "loss.backward()  # retain_graph=True, if you need to call loss.backward() again without optimizer.step()\n",
    "optimizer.step()\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST\n",
    "\n",
    "based on MNIST tutorial: https://github.com/pytorch/examples/blob/master/mnist/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from fashion import FashionMNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "# torch.cuda.init()\n",
    "# torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = FashionMNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "\n",
    "valid_data = FashionMNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = np.random.choice(train_data.train_data.shape[0], 54000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.train_data = train_data.train_data[train_idx, :]\n",
    "train_data.train_labels = train_data.train_labels[torch.from_numpy(train_idx).type(torch.LongTensor)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.ones(60000)\n",
    "mask[train_idx] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data.train_data = valid_data.train_data[torch.from_numpy(np.argwhere(mask)), :].squeeze()\n",
    "valid_data.train_labels = valid_data.train_labels[torch.from_numpy(mask).type(torch.ByteTensor)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "test_batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data,\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    FashionMNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f57f1b94400>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_loader.dataset.train_data[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f57f1dc22b0>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAD3xJREFUeJzt3WuMXPV5x/HfM+tZr3ftFF/CdmOsEBznQqzWoK2pFFRIaCJDo5q0EsIvEiOhOG1D1ah5UUQVlZeobRIhtYrkBDemSkmiJgi/sFqo1YgiUYeF2OZibnEXsFl7HQy+rC97e/pij6MN3vM/y5yZObN5vh/J2tnzzJnzeOzfnJn5n3P+5u4CEE+t6gYAVIPwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IalE7N9Zti71Hfe3c5G+EibU9yfrKnrHc2smJJcl1a0of4WmWrk+7Jeu/VT+fWxsdW5Zcd/Hw2WQdlzqvMY37hfQ/SqZU+M1sk6T7JXVJ+q6735e6f4/6dJ3dVGaTIR3+h08k63d89H9za7tH1ifXXbJoIlnvrk0l62OT3cn6zf3P59b+aehTyXXX3fF0so5L7fU9875vw2/7zaxL0j9LulnS1ZK2mNnVjT4egPYq85l/o6RX3f2Qu49L+oGkzc1pC0CrlQn/aklvzPr9cLbs15jZNjMbMrOhCV0osTkAzdTyb/vdfbu7D7r7YF2LW705APNUJvxHJK2Z9fsV2TIAC0CZ8D8laZ2ZfcjMuiXdLmlXc9oC0GoND/W5+6SZ3SXpPzUz1LfD3fPHddCwp677l2T9jOcP1/35Zel/klrB6//ZxGNL0rGp9PrvTOd/1Lv+hpeS635dv5eso5xS4/zuvlvS7ib1AqCNOLwXCIrwA0ERfiAowg8ERfiBoAg/EFRbz+fH3Mb+9Lpkvbe2L1n/2bn88/1rNp1c92xiHF6SppQ+NfydqfT1GaYS5/t/8X2/TK9747XJetdPn0nWkcaeHwiK8ANBEX4gKMIPBEX4gaAIPxAUQ30d4Mim9HBckWW1/MtjFw3VFb38T3hXwbbPJetFQ4kpw3+UXnftTxt+aIg9PxAW4QeCIvxAUIQfCIrwA0ERfiAowg8ExTh/B9h87c+T9cOTZ5L1Hssfix/z9D/xtKdf/ycK1u+29Cy+quVP0XZgPP/4BElas+HN9GOjFPb8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBUqXF+MxuWdFrSlKRJdx9sRlPRDHSfTNZPT6dfo2vy3Fq30tcKeKfgfP2i6wH0WHoK71pi+8cLLvs90HsqWX8rWUWRZhzk8yl3T1+AHUDH4W0/EFTZ8LukR83saTPb1oyGALRH2bf917v7ETO7XNJjZvaiuz8++w7Zi8I2SepRb8nNAWiWUnt+dz+S/RyV9LCkjXPcZ7u7D7r7YF2NX8wRQHM1HH4z6zOzZRdvS/qspOea1RiA1irztr9f0sNmdvFx/s3d/6MpXQFouYbD7+6HJP1uE3sJ64ruE8n62YJz6i+rjefWegqm6H59sp6sX951OlkvMqbu/FrBNf3X9L6drDPOXw5DfUBQhB8IivADQRF+ICjCDwRF+IGguHR3B5jy9GmzhdNsJ9QLVp0ueP3vraVP2T1fcEpwXfmX9j7v6WHG6YLnRYlTmVGMPT8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBMU4fwfosnLj1alX8G5r/BgBSeopmIJ7omCK767EpbuLpgdfXJtM1qX0MQZIY88PBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0Exzt8BTk/1JOtF4+Epi61oeu/0pb2LLCs43//0ZP7frV5wDMGJifQU3tL5gjpS2PMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCF4/xmtkPS5ySNuvv6bNkKST+UdKWkYUm3uXt6PmXkOjC2Jln/dN/LDT92V8E1/99XS4+V93el9w8np9Nj9bXEFOHLaueS67508vJkfZFeT9aRNp89//ckbXrXsrsl7XH3dZL2ZL8DWEAKw+/uj0s68a7FmyXtzG7vlHRrk/sC0GKNfubvd/eR7PZRSf1N6gdAm5T+ws/dXYlJ08xsm5kNmdnQhC6U3RyAJmk0/MfMbECSsp+jeXd09+3uPujug3UtbnBzAJqt0fDvkrQ1u71V0iPNaQdAuxSG38wekvSkpI+a2WEzu1PSfZI+Y2avSPrD7HcAC0jhOL+7b8kp3dTkXsLa/9YHkvX3/3Z6rP544pT8pbX0tQKKPHjyY8n6n112KFk/NJG/fyk6xuD10RXJ+lWM85fCEX5AUIQfCIrwA0ERfiAowg8ERfiBoLh0dwd4c3hVsr78d3qT9aNTZxve9qOn1ifr//7iNcn6X97wWrKeOqX3g4vSp/T6SLlhSqSx5weCIvxAUIQfCIrwA0ERfiAowg8ERfiBoBjn7wDL93el7/DH6fJ0weW5U54YXZusdx0smCb7hnQ5Nb34qq4lyXVX7m/874Vi7PmBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjG+TvAwMPpy1/r6+lyPXHOfJE3jqxM1ntKDrX31vKnaDvrk8l1V+56IVlPTw6OIuz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCownF+M9sh6XOSRt19fbbsXklfknQ8u9s97r67VU3+pps8eixZv+ATyXqvecPbXvpid7I+mT7lvlCf5Y/lHxxPb3vqnZPlNo6k+ez5vydp0xzLv+XuG7I/BB9YYArD7+6PSzrRhl4AtFGZz/x3mdkBM9thZsub1hGAtmg0/N+WtFbSBkkjkr6Rd0cz22ZmQ2Y2NKH847wBtFdD4Xf3Y+4+5e7Tkr4jaWPivtvdfdDdB+ta3GifAJqsofCb2cCsXz8v6bnmtAOgXeYz1PeQpBslrTKzw5L+TtKNZrZBkksalvTlFvYIoAUKw+/uW+ZY/EALekGOvRfqyfrH6uMNP3b9VPoYAa+VO6F/WS3/rPvdZz5S6rFRDkf4AUERfiAowg8ERfiBoAg/EBThB4Li0t0LwJNj65L161akL3GdMrEsPZQ3VfKgzF7Lf/z/eSv995KOlts4ktjzA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQjPMvAI8e+3iy/tcrXmz4sc9+ID299/SSxqf/lqS65e9fDr2Vnh58NeP8LcWeHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCYpx/ATh2almyXreuhh/b+s8n60u686fYno8u5Z/PPzbaV+qxUQ57fiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IqnCc38zWSHpQUr8kl7Td3e83sxWSfijpSknDkm5z97db12pc515Pj/Pr9xt/7OnJ9Ov/9KJyU3Sn9IxwmEmV5rPnn5T0NXe/WjP/zb5iZldLulvSHndfJ2lP9juABaIw/O4+4u7PZLdPSzooabWkzZJ2ZnfbKenWVjUJoPne02d+M7tS0jWS9krqd/eRrHRUMx8LACwQ8w6/mS2V9GNJX3X3U7Nr7u6a+T5grvW2mdmQmQ1N6EKpZgE0z7zCb2Z1zQT/++7+k2zxMTMbyOoDkkbnWtfdt7v7oLsP1lVy1kcATVMYfjMzSQ9IOuju35xV2iVpa3Z7q6RHmt8egFaZz1jLJyV9QdKzZrYvW3aPpPsk/cjM7pT0mqTbWtMieg+37nCM2qJyl+Yuo+/wnJ8U0SaF4Xf3J6Tck7Jvam47ANqFI/yAoAg/EBThB4Ii/EBQhB8IivADQXFO5QKw9M3WjcUvWjSVrNdqrRuLX3q03GXBUQ57fiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IinH+BaBrvHVj7VOT6em9uxZPlHv8ua/uNoPT+SvFnh8IivADQRF+ICjCDwRF+IGgCD8QFOEHgmKcfwGw9Cn3pfQsGU/Wuxelz7mf8Mabq41XN2cA2PMDYRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCF4/xmtkbSg5L6NXMG9nZ3v9/M7pX0JUnHs7ve4+67W9VoZN0nWzfW/idX7U8/9nT6fP+T0+fT63v+Sfvdb6fX5XT/1prPQT6Tkr7m7s+Y2TJJT5vZY1ntW+7+j61rD0CrFIbf3UckjWS3T5vZQUmrW90YgNZ6T5/5zexKSddI2pstusvMDpjZDjNbnrPONjMbMrOhCV0o1SyA5pl3+M1sqaQfS/qqu5+S9G1JayVt0Mw7g2/MtZ67b3f3QXcfrGtxE1oG0AzzCr+Z1TUT/O+7+08kyd2PufuUu09L+o6kja1rE0CzFYbfzEzSA5IOuvs3Zy0fmHW3z0t6rvntAWiV+Xzb/0lJX5D0rJnty5bdI2mLmW3QzIjMsKQvt6RDqOtceqivbunhuJQ7l+9N1k8XDPWt6upL1k9On8ut1c6mTydu4ZnM0Py+7X9Cks1RYkwfWMA4wg8IivADQRF+ICjCDwRF+IGgCD8QFJfuXgDsyfRpt7f/36dza3v3fzi57kf+4mcN9XTRy98dTNY/8eEjubWpg6+U2jbKYc8PBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0GZJy6t3PSNmR2X9NqsRask/bJtDbw3ndpbp/Yl0VujmtnbB939/fO5Y1vDf8nGzYbcPX2USEU6tbdO7Uuit0ZV1Rtv+4GgCD8QVNXh317x9lM6tbdO7Uuit0ZV0luln/kBVKfqPT+AilQSfjPbZGYvmdmrZnZ3FT3kMbNhM3vWzPaZ2VDFvewws1Eze27WshVm9piZvZL9nHOatIp6u9fMjmTP3T4zu6Wi3taY2X+b2Qtm9ryZ/VW2vNLnLtFXJc9b29/2m1mXpJclfUbSYUlPSdri7i+0tZEcZjYsadDdKx8TNrM/kHRG0oPuvj5b9veSTrj7fdkL53J3/5sO6e1eSWeqnrk5m1BmYPbM0pJulXSHKnzuEn3dpgqetyr2/Bslveruh9x9XNIPJG2uoI+O5+6PSzrxrsWbJe3Mbu/UzH+etsvprSO4+4i7P5PdPi3p4szSlT53ib4qUUX4V0t6Y9bvh9VZU367pEfN7Gkz21Z1M3Poz6ZNl6SjkvqrbGYOhTM3t9O7ZpbumOeukRmvm40v/C51vbtfK+lmSV/J3t52JJ/5zNZJwzXzmrm5XeaYWfpXqnzuGp3xutmqCP8RSWtm/X5FtqwjuPuR7OeopIfVebMPH7s4SWr2c7Tifn6lk2ZunmtmaXXAc9dJM15XEf6nJK0zsw+ZWbek2yXtqqCPS5hZX/ZFjMysT9Jn1XmzD++StDW7vVXSIxX28ms6ZebmvJmlVfFz13EzXrt72/9IukUz3/j/QtLfVtFDTl9XSdqf/Xm+6t4kPaSZt4ETmvlu5E5JKyXtkfSKpP+StKKDevtXSc9KOqCZoA1U1Nv1mnlLf0DSvuzPLVU/d4m+KnneOMIPCIov/ICgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBPX/XX+paSug2lEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_loader.dataset.train_data[10].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FcNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "    \n",
    "    def forward(self, image):\n",
    "        batch_size = image.size()[0]\n",
    "\n",
    "\n",
    "        x = image.view(batch_size, -1)\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-8b3e835d2f81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-136-8b3e835d2f81>\u001b[0m in \u001b[0;36moutputSize\u001b[0;34m(in_size, kernel_size, stride, padding)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moutputSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "def outputSize(in_size, kernel_size, stride, padding):\n",
    "\n",
    "    output = int((in_size - kernel_size + 2*(padding)) / stride) + 1\n",
    "\n",
    "    return(output)\n",
    "\n",
    "print(outputSize([32,28,28],5,1,2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional N dual layers\n",
    "class CNNetworkMultiLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(7 * 7 * 256, 8192)\n",
    "        self.fc2 = nn.Linear(8192, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 128)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(-1, 256 * 7 * 7)\n",
    "        out = self.drop_out(out)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = F.relu(self.fc3(out))\n",
    "        \n",
    "        return F.log_softmax(self.fc4(out), dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         data, target = Variable(data, requires_grad=False).cuda(), Variable(target).cuda() # if you have access to a gpu\n",
    "#         with torch.no_grad():\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)  # calls the forward function\n",
    "        loss = F.nll_loss(output, target)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model, train_loss/len(train_loader.dataset) * 100\n",
    "\n",
    "\n",
    "def valid(model, valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in valid_loader:\n",
    "#         data, target = Variable(data, requires_grad=False).cuda(), Variable(target).cuda() # if you have access to a gpu\n",
    "\n",
    "        data, target = Variable(data, requires_grad=False), Variable(target)\n",
    "        output = model(data)\n",
    "        valid_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    valid_loss /= len(valid_loader.dataset)\n",
    "    print('\\n' + \"valid\" + ' set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        valid_loss, correct, len(valid_loader.dataset),\n",
    "        100. * correct / len(valid_loader.dataset)))\n",
    "    \n",
    "    return 100. * correct / len(valid_loader.dataset), valid_loss\n",
    "\n",
    "    \n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "#         data, target = Variable(data, requires_grad=False).cuda(), Variable(target).cuda() # if you have access to a gpu\n",
    "#         with torch.no_grad():\n",
    "        data, target = Variable(data, requires_grad=False), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\n' + \"test\" + ' set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    \n",
    "def experiment(model, epochs=6, lr=0.001):\n",
    "    best_precision = 0\n",
    "    losses_train = []\n",
    "    losses_validation = []\n",
    "#     best_model = FcNetwork().to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model, train_loss = train(model, train_loader, optimizer)\n",
    "        precision, validation_loss = valid(model, valid_loader)\n",
    "        losses_train.append(train_loss)\n",
    "        losses_validation.append(validation_loss)\n",
    "        if precision > best_precision:\n",
    "            best_precision = precision\n",
    "            best_model = model\n",
    "            \n",
    "   \n",
    "    plt.plot(losses_train, 'blue', label=\"Train\")\n",
    "    plt.plot(losses_validation, 'orange', label=\"Validation\")\n",
    "    plt.ylabel('Average negative log likelihood')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.show()\n",
    "    \n",
    "    return best_model, best_precision\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid set: Average loss: 0.4015, Accuracy: 5130/6000 (85%)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-ecc0424cebac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mFcNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# add your models in the list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#     model.cuda()  # if you have access to a gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_precision\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mbest_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-144-1ed95c7ddc3c>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(model, epochs, lr)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mlosses_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-144-1ed95c7ddc3c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#         data, target = Variable(data, requires_grad=False).cuda(), Variable(target).cuda() # if you have access to a gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#         with torch.no_grad():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \"\"\"\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \"\"\"\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_tensor_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tensor is not a torch image.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# TODO: make efficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36m_is_tensor_image\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_tensor_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36mis_tensor\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mObject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mObject\u001b[0m \u001b[0mto\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \"\"\"\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_precision = 0\n",
    "# device = torch.device(\"cpu\")\n",
    "# best_model = FcNetwork().to(device)\n",
    "\n",
    "\n",
    "for model in [FcNetwork()]:  # add your models in the list\n",
    "#     model.cuda()  # if you have access to a gpu\n",
    "    model, precision = experiment(model)\n",
    "    if precision > best_precision:\n",
    "        best_precision = precision\n",
    "        best_model = model\n",
    "\n",
    "test(best_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
