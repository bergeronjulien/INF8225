{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction a PyTorch\n",
    "\n",
    "Based on https://github.com/mila-udem/welcome_tutorials/tree/master/pytorch By Sandeep Subramanian, https://github.com/jcjohnson/pytorch-examples by Justin Johnson and official documentation http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor\n",
    "\n",
    "Tensors are similar to numpy array, but they can also be used on GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "# convert numpy array to tensor\n",
    "torch.from_numpy(np.array([1,2,3,4]))  # LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.], dtype=torch.float64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.array([1.,2,3,4]))  # Double Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor([1,2,3,4])\n",
    "torch.Tensor([1,2,3,4])  # float tensor by default, can change it with torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([1,2,3,4])\n",
    "# HI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.4142, 1.7321, 2.0000])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sqrt()  # similar functionality as numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "x = x.view(-1, 1)  # the torch reshape function\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [2., 2.],\n",
       "        [3., 3.],\n",
       "        [4., 4.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([x, x], 1)  # concatenate 2 vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "\n",
    "Autograd provides automatic differentiation on all operations perform on tensors. To be able to use Autograd, you must wrap your tensors in a Variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], requires_grad=True)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(x, requires_grad=False)\n",
    "w = Variable(torch.ones(4, 1), requires_grad=True)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "dot: Expected 1-D argument self, but got 2-D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-2cfa5d8249c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dot: Expected 1-D argument self, but got 2-D"
     ]
    }
   ],
   "source": [
    "z = torch.dot(w, x)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optim and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([w], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'z' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-d1156426382c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'z' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "z.backward()\n",
    "print(w.grad)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.9900\n",
      " 0.9800\n",
      " 0.9700\n",
      " 0.9600\n",
      "[torch.FloatTensor of size 4x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "dot: Expected 1-D argument self, but got 2-D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-2cd26b6fc9ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dot: Expected 1-D argument self, but got 2-D"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.MSELoss()\n",
    "z = torch.dot(w, x)\n",
    "target = Variable(torch.zeros(1))\n",
    "optimizer.zero_grad()\n",
    "loss = loss_fn(z, target)\n",
    "loss.backward()  # retain_graph=True, if you need to call loss.backward() again without optimizer.step()\n",
    "optimizer.step()\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST\n",
    "\n",
    "based on MNIST tutorial: https://github.com/pytorch/examples/blob/master/mnist/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from fashion import FashionMNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "# torch.cuda.init()\n",
    "# torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = FashionMNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "\n",
    "valid_data = FashionMNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = np.random.choice(train_data.train_data.shape[0], 54000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.train_data = train_data.train_data[train_idx, :]\n",
    "train_data.train_labels = train_data.train_labels[torch.from_numpy(train_idx).type(torch.LongTensor)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.ones(60000)\n",
    "mask[train_idx] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data.train_data = valid_data.train_data[torch.from_numpy(np.argwhere(mask)), :].squeeze()\n",
    "valid_data.train_labels = valid_data.train_labels[torch.from_numpy(mask).type(torch.ByteTensor)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "test_batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data,\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    FashionMNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f57f2b04f98>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAElFJREFUeJzt3W1wXNV5B/D/s6tdSZblF2EkK8LYxjFhbJrYqWJacCkpITU0GUPaofGH1p3JxOkUpqWTD2XoTMNMvzCdhkzSSTPjFBfToYROA8XTuCHU6YQwJa6FARvbYBsiYwvJ78h612r36QddU2F0nrvet7vu8//NaLTaZ+/u2Sv9dXf33HOOqCqIyJ9U0g0gomQw/EROMfxETjH8RE4x/EROMfxETjH8RE4x/EROMfxETjXU8sGy0qhNaKnlQxK5Mo4RTOqEFHPbssIvIhsAfBtAGsA/qOoj1u2b0IKb5PZyHpKIDLt1V9G3Lfllv4ikAXwXwJ0AVgHYJCKrSr0/Iqqtct7zrwNwVFXfUdVJAD8AsLEyzSKiaisn/F0Ajs/4+UR03YeIyBYR6RGRnhwmyng4Iqqkqn/ar6pbVbVbVbszaKz2wxFRkcoJfx+AJTN+via6joiuAOWEfw+AlSKyXESyAL4MYEdlmkVE1VZyV5+qTonI/QCex3RX3zZVPVCxlhFRVZXVz6+qOwHsrFBbiKiGeHovkVMMP5FTDD+RUww/kVMMP5FTDD+RUww/kVMMP5FTDD+RUww/kVMMP5FTDD+RUww/kVMMP5FTDD+RUww/kVMMP5FTDD+RUww/kVMMP5FTDD+RUww/kVMMP5FTDD+RUww/kVMMP5FTDD+RUww/kVMMP5FTZa3SKyK9AIYA5AFMqWp3JRpFVBGpdOnbaiGmrqXfNwBpCEcvd+unzG0b+wbD99v7UtFtKCv8kc+q6pkK3A8R1RBf9hM5VW74FcBPROQVEdlSiQYRUW2U+7J/var2iUg7gBdE5E1VfXHmDaJ/ClsAoAlzynw4IqqUso78qtoXfT8F4FkA62a5zVZV7VbV7gway3k4IqqgksMvIi0i0nrxMoDPA3ijUg0jouoq52V/B4BnReTi/fyzqv64Iq0ioqorOfyq+g4Au0OSkhfX113Il3X3n3nN3v7pH68P1hb/j92XPueZ3SW16QNlPrdq0qmpYK3x9V+a2xaWfyx8vykpug3s6iNyiuEncorhJ3KK4SdyiuEncorhJ3KqEqP6qJ7FDU0t05zUpFm/74v/EaxN/E7G3PaPv7PPrK/9twfM+g3fCQ82zR9+29y2XAN/frNZ7/798HPb+8QN5rbtf//f4aKOm9vOxCM/kVMMP5FTDD+RUww/kVMMP5FTDD+RUww/kVPs5///LmaK6VRTk1kvjNv9xk8+dbtZb/+tvmBteMKe2enwSIdZv/+2F8z6p+/sDdZuay7v/IevHr/FrF+j9jkKE4Vw9OYfy5XUpsvFIz+RUww/kVMMP5FTDD+RUww/kVMMP5FTDD+RU+zndy6uHz/Osn+0x8Uv/VJ4Oelf9C81tz143u7nv77lpFkf0Wyw9viFeea2C9KjZn1N67tmfevh8JTlADB0oTlYW/mjPea2lcIjP5FTDD+RUww/kVMMP5FTDD+RUww/kVMMP5FTsf38IrINwBcAnFLVG6Pr2gA8DWAZgF4A96rq+eo1k+rVe7+3wqyvzfw8WMvl7eXDVy2y+/H/cP6rZv3poRuDtSaxx8y3ZsbM+s/O3WTWR0ftuQruuOFQsHZisX1+w9SAvV+KVcyR/3EAGy657kEAu1R1JYBd0c9EdAWJDb+qvgjg3CVXbwSwPbq8HcDdFW4XEVVZqe/5O1S1P7o8AMB+nUJEdafsD/xUVQEEJ4oTkS0i0iMiPTlMlPtwRFQhpYb/pIh0AkD0/VTohqq6VVW7VbU7A/tDECKqnVLDvwPA5ujyZgDPVaY5RFQrseEXkacAvAzgEyJyQkS+AuARAHeIyBEAn4t+JqIrSGw/v6puCpTsCdupPojY9Zh5/RuWLjHr7ffY49p39V8frM1vtucS2NT+C7P+r0OrzfqZXGuwdn1Tf7AGAMdzV5n1gtr7NZOdMuv9Y/PDxXRtzr3jGX5ETjH8RE4x/EROMfxETjH8RE4x/ERO1dfU3XHdUtUU0+WVqHK668p8Xgf/yh62cZ0GT+4EAEzkwn9in+06Ym57dmquWc+pPSQ4LeFluOel7W7GV0ftacWzqbxZXzjXnvr7wkR4afSWTHnLhxeLR34ipxh+IqcYfiKnGH4ipxh+IqcYfiKnGH4ip+qsnz/mf5HWpv+z4lJ2f3Ssgt2nbEkvMIaOAnjzr28w66nspFn/5YGPmfWG9vAU2L8x77C57VvjnWZ9Tspu28KGkfC2Yk8pd2hosVlPiX3+RNy05HMz4bYf/9K15radj9rDqIvFIz+RUww/kVMMP5FTDD+RUww/kVMMP5FTDD+RU/XVzx/Xn22Nay9z3Lo0xOwK4xwEzdn9zeX00xdj5HfDy0X33Wk/dsM5+/9/Y1+zWR+/yt7vv3nd0WBtMmY8fl7ttsWN55+ftsfUW0ansmY9m7Kn5r4wEh6vDwDtLcPB2oLftqcVx6N2uVg88hM5xfATOcXwEznF8BM5xfATOcXwEznF8BM5FdvPLyLbAHwBwClVvTG67mEAXwVwOrrZQ6q6s+zWlLmcdDl0yu63rSa9+VNm/egmu88Y83LBUvZ4o7npgrfsu27b/75ZP/ENe/v72n8arO0c+qS5bQH230NjKvy8AeDdyfAy24sz9vNa1nLOrO87Z89jEOfMaEuwdkvHO+a2b5T1yP+nmCP/4wA2zHL9t1R1TfRVfvCJqKZiw6+qLwKw/w0S0RWnnPf894vIPhHZJiILK9YiIqqJUsP/PQArAKwB0A/gm6EbisgWEekRkZ4c7HnTiKh2Sgq/qp5U1byqFgB8H8A647ZbVbVbVbszsD98IqLaKSn8IjJzWtV7ULkPIImoRorp6nsKwG0AFonICQDfAHCbiKwBoAB6AXytim0koiqIDb+qbprl6sdKfsQqjcmXjD3+OnbMfYz0onCf8civrzC3Pf1Jeze39NvPe8nz9pj8VC78Aq5pwO7P1pT94u/NP51j1v997d+Z9eeHVwdrbQ3hMe0AkNOY/ZayP0Na3ng6WLsqFZ7Tf/qxY+YSKMTMg5C1zxs5+/7cYO2mj79tbvtm1y3BmpzMmNvOxDP8iJxi+ImcYviJnGL4iZxi+ImcYviJnKr91N1Gd1563jxz08JoeCrm3K2/Ym7b+0W7C0Tax816fiS8feasPYV080mzjIYxu6tvuMu+/8n54V/j2Ofs551faA+LXdR+waw/eT48bTgAzEmHu1hHC3b3bGfMsNuj4x1mvckY8ntgtMvcdixv77cV88+a9d4LbWZ9eDg8TPv0lJ2D8U+Ely4vDLKrj4hiMPxETjH8RE4x/EROMfxETjH8RE4x/ERO1bafXwTSGJ7NZ2r1cnPzhsPHw7Vdr5jbfvyn9jTQhVvXmPWBdeH+0+yg3U+fj5nA6P3r7f/B49faw5EXdYT74scGw1NEA8DqrgGzPpG3/0R+dCw8ZBcAChre74WC/TtJpwtmvW3OmFk/Mxx+7qPvhYfUAkDmavu+83n7d9ZwxB4KnZHw30zTr9rnXgwuD58fkX89Zvr7GXjkJ3KK4SdyiuEncorhJ3KK4SdyiuEncorhJ3Kqpv38ks0gdW14HHUhFdNHuSg8RjrdHp5aGwBk2O63nfrZq2a9YfXNwdrEBnvMu7w836w32UPDoSl73Hv+6vB+W9ph37nVDw8A17WeMes3L7KXk26U0pc+H8w3m/W2hrjpt8PzIBzubDe37WgcMutrWt4165lu+3nvHgpP974sG55yHACMUwRiFjX/MB75iZxi+ImcYviJnGL4iZxi+ImcYviJnGL4iZwSjVkWW0SWAHgCQAcABbBVVb8tIm0AngawDEAvgHtV9bx1X/Nau/Qza/8kWB9aFp7LHABaj4eXZM4M2P2yhbn2oPr0gNl06Pzw+O+BR+ze1easPT47bXXcAhiZtOdit8a1X9Niz33/3oh9DsKFSXu/vT9sj1ufyoX72rON9n4ZPW/38ze+Z++X9Fj499IQXgJiettJ+3fSdM6uZ0bsuQgazxrLi8ec79Jw8Fiw9vLgsxicOl1Ud38xR/4pAF9X1VUAfg3AfSKyCsCDAHap6koAu6KfiegKERt+Ve1X1b3R5SEAhwB0AdgIYHt0s+0A7q5WI4mo8i7rPb+ILAOwFsBuAB2q2h+VBjD9toCIrhBFh19E5gL4IYAHVPVDJ7Pr9AcHs74JEpEtItIjIj2TOftcbCKqnaLCLyIZTAf/SVV9Jrr6pIh0RvVOAKdm21ZVt6pqt6p2ZzP2ZJJEVDux4RcRAfAYgEOq+uiM0g4Am6PLmwE8V/nmEVG1FNPVtx7AzwHsB3Cx/+IhTL/v/xcA1wI4humuvnPWfc2TNr1Jbg/WC+vt6bOHl4S7AlN5c1PEjFzFVLN9g7YDw+HHHozpNxqIGaLZak8jHUcnjG6jmN+vjtlLk2ve3rGpZrt7VvPhLi9pKHNEedo+dklTuG3aandRFubYw6gh9t9LvjlmSfip8H7RbMwx2ehF3LP3u7gw1FdUV1/s3lfVlxAeJhxOMhHVNZ7hR+QUw0/kFMNP5BTDT+QUw0/kFMNP5FRtl+iOkXrpNbM+z6g1LLaHFhQW21N7jy+2zz4cXBmuj3S2mtumx+y2NYzZffGXNR/zpZvGnP8QM5oYebu7uqy2acyhJ65tceduiNEfHrdf4toWp2HCbnzaqOez9hNrfdc4r+My8MhP5BTDT+QUw0/kFMNP5BTDT+QUw0/kFMNP5FTt+/lT4amcofZ0x9bY9KmBk/a2MfWY0dtmfcEce2y4xIx5l2zMo8eMyTfHlseNmY+774y9vcaMqTfFjImXXMzy3sZcAQDsKbDTxt8hAI2ZPju2bZP2tORaiGm7IX/KmB+iYC9FPxOP/EROMfxETjH8RE4x/EROMfxETjH8RE4x/ERO1b6fvxAzkPoKVBiNmbc/rk6UAB75iZxi+ImcYviJnGL4iZxi+ImcYviJnGL4iZyKDb+ILBGR/xKRgyJyQET+LLr+YRHpE5HXoq+7qt9cIqqUYk7ymQLwdVXdKyKtAF4RkRei2rdU9W+r1zwiqpbY8KtqP4D+6PKQiBwC0FXthhFRdV3We34RWQZgLYDd0VX3i8g+EdkmIgsD22wRkR4R6cmhMssMEVH5ig6/iMwF8EMAD6jqBQDfA7ACwBpMvzL45mzbqepWVe1W1e4MGivQZCKqhKLCLyIZTAf/SVV9BgBU9aSq5lW1AOD7ANZVr5lEVGnFfNovAB4DcEhVH51xfeeMm90D4I3KN4+IqqWYT/tvAfAHAPaLyMU1tB8CsElE1gBQAL0AvlaVFhJRVRTzaf9LmH0V9p2Vbw4R1QrP8CNyiuEncorhJ3KK4SdyiuEncorhJ3KK4SdyiuEncorhJ3KK4SdyiuEncorhJ3KK4SdyiuEnckpUtXYPJnIawLEZVy0CcKZmDbg89dq2em0XwLaVqpJtW6qqVxdzw5qG/yMPLtKjqt2JNcBQr22r13YBbFupkmobX/YTOcXwEzmVdPi3Jvz4lnptW722C2DbSpVI2xJ9z09EyUn6yE9ECUkk/CKyQUTeEpGjIvJgEm0IEZFeEdkfrTzck3BbtonIKRF5Y8Z1bSLygogcib7PukxaQm2ri5WbjZWlE9139bbidc1f9otIGsBhAHcAOAFgD4BNqnqwpg0JEJFeAN2qmnifsIjcCmAYwBOqemN03d8AOKeqj0T/OBeq6l/USdseBjCc9MrN0YIynTNXlgZwN4A/QoL7zmjXvUhgvyVx5F8H4KiqvqOqkwB+AGBjAu2oe6r6IoBzl1y9EcD26PJ2TP/x1FygbXVBVftVdW90eQjAxZWlE913RrsSkUT4uwAcn/HzCdTXkt8K4Cci8oqIbEm6MbPoiJZNB4ABAB1JNmYWsSs319IlK0vXzb4rZcXrSuMHfh+1XlU/DeBOAPdFL2/rkk6/Z6un7pqiVm6ulVlWlv5Akvuu1BWvKy2J8PcBWDLj52ui6+qCqvZF308BeBb1t/rwyYuLpEbfTyXcng/U08rNs60sjTrYd/W04nUS4d8DYKWILBeRLIAvA9iRQDs+QkRaog9iICItAD6P+lt9eAeAzdHlzQCeS7AtH1IvKzeHVpZGwvuu7la8VtWafwG4C9Of+L8N4C+TaEOgXdcBeD36OpB02wA8hemXgTlMfzbyFQBXAdgF4AiA/wTQVkdt+ycA+wHsw3TQOhNq23pMv6TfB+C16OuupPed0a5E9hvP8CNyih/4ETnF8BM5xfATOcXwEznF8BM5xfATOcXwEznF8BM59b/hX46u5hszrwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_loader.dataset.train_data[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f57f2321978>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_loader.dataset.train_data[10].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FcNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "    \n",
    "    def forward(self, image):\n",
    "        batch_size = image.size()[0]\n",
    "\n",
    "\n",
    "        x = image.view(batch_size, -1)\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-8b3e835d2f81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-113-8b3e835d2f81>\u001b[0m in \u001b[0;36moutputSize\u001b[0;34m(in_size, kernel_size, stride, padding)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moutputSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "def outputSize(in_size, kernel_size, stride, padding):\n",
    "\n",
    "    output = int((in_size - kernel_size + 2*(padding)) / stride) + 1\n",
    "\n",
    "    return(output)\n",
    "\n",
    "print(outputSize([32,28,28],5,1,2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional N dual layers\n",
    "class CNNetworkMultiLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(7 * 7 * 256, 8192)\n",
    "        self.fc2 = nn.Linear(6072, 2024)\n",
    "        self.fc3 = nn.Linear(1024, 128)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(-1, 64 * 7 * 7)\n",
    "        out = self.drop_out(out)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = F.relu(self.fc3(out))\n",
    "        \n",
    "        return F.log_softmax(self.fc4(out), dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         data, target = Variable(data, requires_grad=False).cuda(), Variable(target).cuda() # if you have access to a gpu\n",
    "#         with torch.no_grad():\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)  # calls the forward function\n",
    "        loss = F.nll_loss(output, target)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model, train_loss/len(train_loader.dataset) * 100\n",
    "\n",
    "\n",
    "def valid(model, valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in valid_loader:\n",
    "#         data, target = Variable(data, requires_grad=False).cuda(), Variable(target).cuda() # if you have access to a gpu\n",
    "\n",
    "        data, target = Variable(data, requires_grad=False), Variable(target)\n",
    "        output = model(data)\n",
    "        valid_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    valid_loss /= len(valid_loader.dataset)\n",
    "    print('\\n' + \"valid\" + ' set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        valid_loss, correct, len(valid_loader.dataset),\n",
    "        100. * correct / len(valid_loader.dataset)))\n",
    "    \n",
    "    return 100. * correct / len(valid_loader.dataset), valid_loss\n",
    "\n",
    "    \n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "#         data, target = Variable(data, requires_grad=False).cuda(), Variable(target).cuda() # if you have access to a gpu\n",
    "#         with torch.no_grad():\n",
    "        data, target = Variable(data, requires_grad=False), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\n' + \"test\" + ' set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    \n",
    "def experiment(model, epochs=6, lr=0.001):\n",
    "    best_precision = 0\n",
    "    losses_train = []\n",
    "    losses_validation = []\n",
    "#     best_model = FcNetwork().to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model, train_loss = train(model, train_loader, optimizer)\n",
    "        precision, validation_loss = valid(model, valid_loader)\n",
    "        losses_train.append(train_loss)\n",
    "        losses_validation.append(validation_loss)\n",
    "        if precision > best_precision:\n",
    "            best_precision = precision\n",
    "            best_model = model\n",
    "            \n",
    "   \n",
    "    plt.plot(losses_train, 'blue', label=\"Train\")\n",
    "    plt.plot(losses_validation, 'orange', label=\"Validation\")\n",
    "    plt.ylabel('Average negative log likelihood')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.show()\n",
    "    \n",
    "    return best_model, best_precision\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_precision = 0\n",
    "# device = torch.device(\"cpu\")\n",
    "# best_model = FcNetwork().to(device)\n",
    "\n",
    "\n",
    "for model in [CNNetworkMultiLayer()]:  # add your models in the list\n",
    "#     model.cuda()  # if you have access to a gpu\n",
    "    model, precision = experiment(model)\n",
    "    if precision > best_precision:\n",
    "        best_precision = precision\n",
    "        best_model = model\n",
    "\n",
    "test(best_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
